Time to extract patent data: 0:01:55.826517
Dimensions of patent dataset: (309360, 6)
Dimension of labels dataset: (261733, 2)
Number of unique labels: 589
Shape of labels dataset after removal of low count labels: (213577, 2)
Dimensions of patent dataset after merging on labels: (309360, 7)
Dimensions of patent data after dropping nan: (213577, 7)
Number of unique labels on final dataset: 7
Length of labels vector: 213577
Number of classes: 7
Maximum length of texts: 20867
Using TensorFlow backend.
Found 139041 unique tokens.
Shape of data tensor: (213577, 5000)
Shape of label tensor: (213577,)
Dimensions of training data (x_train, y_train): (180000, 5000) (180000,)
Dimensions of validation data (x_val, y_val): (20000, 5000) (20000,)
Dimensions of (vectorized) y_train_vec: (180000, 7)
Dimensions of (vectorized) y_val_vec: (20000, 7)
Found 400000 word vectors.
Dimensions of Embedding Matrix: (80000, 300)
How many words in our set have no embedding vector: 37038
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 5000, 300)         24000000  
_________________________________________________________________
gru_1 (GRU)                  (None, 100)               120300    
_________________________________________________________________
dense_1 (Dense)              (None, 7)                 707       
=================================================================
Total params: 24,121,007
Trainable params: 121,007
Non-trainable params: 24,000,000
_________________________________________________________________
Train on 180000 samples, validate on 20000 samples
Epoch 1/3
180000/180000 [==============================] - 18730s 104ms/step - loss: 0.6850 - acc: 0.7363 - val_loss: 0.5080 - val_acc: 0.8040
Epoch 2/3
180000/180000 [==============================] - 18722s 104ms/step - loss: 0.5134 - acc: 0.8048 - val_loss: 0.4660 - val_acc: 0.8216
Epoch 3/3
180000/180000 [==============================] - 18785s 104ms/step - loss: 0.4841 - acc: 0.8161 - val_loss: 0.4576 - val_acc: 0.8254

np.bincount(y_train) / y_train.shape[0]
Out[2]: 
array([0.13424444, 0.08173889, 0.05995   , 0.01109444, 0.04667222,
       0.29622778, 0.37007222])

np.bincount(y_val) / y_val.shape[0]
Out[3]: array([0.1301 , 0.08245, 0.05765, 0.0119 , 0.04825, 0.29985, 0.3698 ])


              precision    recall  f1-score   support

           0       0.86      0.86      0.86      2602
           1       0.74      0.79      0.76      1649
           2       0.71      0.74      0.72      1153
           3       0.88      0.75      0.81       238
           4       0.84      0.78      0.81       965
           5       0.84      0.79      0.81      5997
           6       0.84      0.87      0.86      7396

   micro avg       0.83      0.83      0.83     20000
   macro avg       0.82      0.80      0.80     20000
weighted avg       0.83      0.83      0.83     20000