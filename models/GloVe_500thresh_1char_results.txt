Time to extract patent data: 0:01:58.108272
Dimensions of patent dataset: (309360, 6)
Dimension of labels dataset: (261733, 2)
Number of unique labels: 589
Shape of labels dataset after removal of low count labels: (213577, 2)
Dimensions of patent dataset after merging on labels: (309360, 7)
Dimensions of patent data after dropping nan: (213577, 7)
Number of unique labels on final dataset: 7
Length of labels vector: 213577
Number of classes: 7
Maximum length of texts: 20867
Using TensorFlow backend.
Found 139041 unique tokens.
Shape of data tensor: (213577, 5000)
Shape of label tensor: (213577,)
Dimensions of training data (x_train, y_train): (180000, 5000) (180000,)
Dimensions of validation data (x_val, y_val): (20000, 5000) (20000,)
Dimensions of (vectorized) y_train_vec: (180000, 7)
Dimensions of (vectorized) y_val_vec: (20000, 7)
Found 400000 word vectors.
Dimensions of Embedding Matrix: (80000, 300)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 5000, 300)         24000000  
_________________________________________________________________
gru_1 (GRU)                  (None, 100)               120300    
_________________________________________________________________
dense_1 (Dense)              (None, 7)                 707       
=================================================================
Total params: 24,121,007
Trainable params: 121,007
Non-trainable params: 24,000,000
_________________________________________________________________
Train on 180000 samples, validate on 20000 samples
Epoch 1/3
180000/180000 [==============================] - 16759s 93ms/step - loss: 0.6812 - acc: 0.7366 - val_loss: 0.4980 - val_acc: 0.8103
Epoch 2/3
180000/180000 [==============================] - 16735s 93ms/step - loss: 0.5006 - acc: 0.8085 - val_loss: 0.4667 - val_acc: 0.8216
Epoch 3/3
180000/180000 [==============================] - 16906s 94ms/step - loss: 0.4713 - acc: 0.8205 - val_loss: 0.4463 - val_acc: 0.8330
Time to execute  14:00:01.108501


np.bincount(y_train) / y_train.shape[0]
Out[6]: 
array([0.13421111, 0.08194444, 0.05957222, 0.01122778, 0.04668889,
       0.29730556, 0.36905   ])

np.bincount(y_val) / y_val.shape[0]
Out[7]: array([0.13455, 0.0806 , 0.0578 , 0.01235, 0.04735, 0.2925 , 0.37485])



Classification Report on validation data: 

               precision    recall  f1-score   support

           0       0.87      0.84      0.86      2691
           1       0.80      0.75      0.77      1612
           2       0.72      0.73      0.72      1156
           3       0.87      0.76      0.81       247
           4       0.81      0.83      0.82       947
           5       0.83      0.82      0.82      5850
           6       0.85      0.88      0.86      7497

   micro avg       0.83      0.83      0.83     20000
   macro avg       0.82      0.80      0.81     20000
weighted avg       0.83      0.83      0.83     20000
